# Identification
### MorseCode App
#### CSCI 4176 Mobile Computing Project (Fall 2018)
Group 16:
* Dinesh Sai Bayireddi   B00791584
* George Faraj           B00638341
* Paul Duchesne          B00332119
* Samarth Raval          B00812673
* Tom Smith              B00694293

For questions about this project send an email to [Paul](mailto:paulduchesne1337@gmail.com).

This project used GitHub for version control and can be accessed [here](https://github.com/PJDuchesne/MorseCode).

# Project Summary

The main concept behind this application is to provide a method for users to better understand Morse code.
The key features of this application include, allow the user to translate text to Morse code and vice versa, and follow a set series of lessons to learn Morse code.
The progress of the aforementioned lessons can be tracked if the users makes an account (another key feature of the application).
The way the lessons work is by introducing text and have the user tap it into the phone as Morse. The text that gets presented to the user becomes more complex as the user progresses through the different lessons.
The application's UI was designed to not include the default action bar and customized to still feel like an android application.
The UI design combined with the methods for free style input and translation was intended to encourage a certain level of immersion and hopefully boost the user's learning experience.

## Libraries
**Components/Widget Libraries (Button,TextView,ListView,ProgressBar ...):** This project makes use of several components and widgets native to Android.
The code for interacting with these were a result of what was learned in the CSCI 4176 labs and prior experience with Android application development.

**camera2/CameraManager :** The CameraManager is part of the hardware library native to Android and was used to generate visual feedback via the front facing flashlight most Android devices have. This was achieved with the setTorchMode function, source [here](https://developer.android.com/reference/android/hardware/camera2/CameraManager)

**Vibrator :** The vibrator class is part of the OS library native to Android it was used to generate haptic feedback. This was achieved with the vibrate and cancel functions, source [here](https://developer.android.com/reference/android/os/Vibrator)

**FirebaseUser, FirebaseAuth, FirebaseDatabase :** This project used Google's Firebase to handle user account creation and access, as well as storage of user information.
Each FirebaseUser contains a unique key generated by the API which points to a object in the database containing a set of key value pairs where the key is the lesson number (zero indexed) and the value is a boolean on whether or not it was completed.
While not the most efficient method of storing the data generated by the application, the API's documentation and a group member's prior experience with the Firebase library greatly reduced development time which was the most limiting factor in this project.
The tutorial used for references can be found [here](https://firebase.google.com/docs/android/setup).

**ArrayList:** The ArrayList data structure is native to Java. It was used to build arrays of Strings in conjunction with ListViews' and GridViews' .setArrayAdapter functions to populate the screen with data and display it to the user.
The code for using this library was intuitive and did not require external sourcing.

## Installation Notes
This version of the application will run on the same version/settings of the emulator used in the CSCI 4176 Labs. There have been adjustments to the gradle file to include foreign libraries and the Build Tools version 28.0.3 is needed but the compiler will handle these installations, if needed, at the users request.
Please note: The vibration and flash components work and have been tested on several physical devices. However, the android studio emulator does not have anyway of outputting if the phone's light is on/off or if the device is/isn't vibrating.


## Code Examples

**Problem 1: PAUL WITH THE DELAY THING ADD THE TAILCHAIN SOLUTION**

EXPLAIN THE HEAD TAIL SOLUTION.
```
// The method we implemented that solved our problem
public static VOID THING(VOID * THING?) {
    //YOUR CODE HERE
}

// Source: YOUR MIND
```

**Problem 2: Using Custom Made Sounds With Varying Frequency**

Since outputting sound from a static MP3/WAV file limits user freedom the AudioTrack library to generate tones of varying frequencies.
Despite the online documentation provided by android on this library it's usage was tricky as it required generating an array of bytes that represent sound waves.
To make up for lack of experience with generating such a structure an online tutorial for creating an 8-bit music generating app was followed (link below).
The generateSound function (shown below) from the tutorial solved the problem with using AudioTrack.
```
private void generateSound(int frequency, int duration) {
    int sampleRate = 44100;
    soundData = new byte[sampleRate * duration];
    for (int i = 0; i < soundData.length; i++) {
        byte sample = (byte) ( Math.sin(2 * Math.PI * frequency * i / sampleRate) * 255 );
        soundData[i] = sample;
    }
}
// Source: Progur.com How to Create 8-bit Music on Android [1]
```

**Problem 3.1: Efficiently Decoding Morse to Letters**

Morse encoding and decoding could be done using a Trie structure given the binary nature of Morse code.
The end result was something very similar to a standard Hoffman encoding.
The flow of the algorithm developed is illustrated in the image below:

![Morse Trie Search Algorithm](https://github.com/PJDuchesne/MorseCode/blob/georgeRefactor/ProjectDocumentation/MorseTrieBranchAlgorithm_Diagram.png "Morse Trie Search")


**Problem 3.2: Checking if the Mobile Device has a Flash Camera**

While using the flashlight of the mobile device was as simple as calling setTorchMode function of the CameraManager class as specified by the android documentation (sourced below) it would cause the emulator to crash.
The reason for this was not identified for a long time. It turned out that the setTorchMode crashes the emulator as the emulator does not have the resources for a flashlight.
This was made known thanks to a StackOverflow post (sourced below) which indicated a method of checking system features (modified and shown below) as well as documentation for checking other device features (also sourced below).

```
//This demonstrates the use of a boolean check that will essentially indicate if the activity will crash or not if setTorchMode was called.
   if( getApplicationContext().getPackageManager().hasSystemFeature(PackageManager.FEATURE_CAMERA_FLASH) ){
        //It is safe to use setTorchMode
   }
   else{
        //Do not use setTorchMode else the activity will crash
   }

// Source: Android Camera2 Library Documentation [2], StackOverflow Checking Flash Post [3], Android Hardware Features Documentation [4]
```

## Feature Section
List all the main features of your application with a brief description of each feature.

**Morse Feedback :** Whenever a user is engaging with an activity requiring Morse input or output the device will generate feedback representing the respective Morse code based on their settings.

The following use case illustrates this:
1. The user goes to the settings page sets a low sound frequency and sets haptic feedback to false.
2. The user goes to the Text to Morse page and enters text and clicks the Generate Morse button.
3. The device will output a sound and flash representing the dots and dash representation of the

**Morse Translation :** The application has two pages accessible from the landing page. One where the user is shown a button to enter Morse code and they can see the textual representation as they type and another where they can enter text and see the Morse representation of said text upon clicking the Generate Morse button.

We know that this function of the application works due to the Text To Morse and Morse To Text pages displaying appropriate functionality.

**User Account System :** The application supports the creation of an account with an email and a password of at least 6 characters.

The following use case illustrates this:
1. A user goes to the login page and registers for an account.
2. The user is now logged in and completes lessons 1-3.
3. The user logs out and shuts off the application.
4. Upon restarting the application the user logs in and clicks on the lessons page and will see that lessons 1-3 are marked as completed.

## Final Project Status
Overall the project was a success, while the "Bonus" functionality (outlined below) was a bit out of reach even for future iterations all "Expected" and "Basic" functionality were accomplished with the opportunity to be expanded if desired.
A possible improvements for the application would be to remove Firebase and use a MySQL server to increase performance. Given the modular nature of the UserInfo class this migration could be done given the right amount of time.
Another possible improvement would be to add the option to change the Morse code standard that the user wishes to learn which would require updating the usage of the MorseCodeStandards class and the class itself.

Our original scope of the applications intended functionality is as follows:

#### Minimum Functionality
- Input Morse code as taps and display corresponding text. (Completed)
- Take input text and translate it into Morse code as text, audio, and haptic feedback. (Completed)
- Provide an options page to modify timing parameters for Morse code I/O. (Completed)

#### Expected Functionality
- Training course for learning Morse code (With a minimum of 5 lessons). (Completed)
- User login and corresponding database, which stores basic analytics. (Completed)
- Output Morse code as light using the phoneâ€™s flashlight. (Completed)

#### Bonus Functionality
- Advanced account analytics. (Not Implemented)
- Provide an option to input Morse code as light. (Not Implemented)
- Implement two-way Morse Code communication between two phones. (Not Implemented)
- Utilize Googleâ€™s audio and visual API to provide audio and visual inputs. (Not Implemented)


## Sources
What to include in your project sources:
- Stock images
- Design guides
- Programming tutorials
- Research material
- Android libraries
- Everything listed on the Dalhousie Plagiarism and Cheating pages(https://www.dal.ca/dept/university_secretariat/academic-integrity/plagiarism-cheating.html)

- The firebase documentation used can be found in the following page: https://firebase.google.com/docs/android/setup
  - Note: while the link doesn't contain all the references used it does intuitively redirect to these pages.


[1] "How to Create 8-bit Music on Android", progur.com, 11 December 2016. [Online]. Available: https://progur.com/2016/12/how-to-create-8-bit-music-on-android.html.

[2] "Android Camera2 Library Documentation", developer.android.com, 6 June 2018. [Online]. Available: https://developer.android.com/reference/android/hardware/camera2/CameraManager

[3] "StackOverflow Checking Flash Post", stackoverflow.com, 12 November 2012. [Online] Available: https://stackoverflow.com/questions/13413938/how-to-check-if-device-has-flash-light-led-android

[4] "Android Hardware Features Documentation", developer.android.com, 20 November 2018. [Online] Available: https://developer.android.com/guide/topics/manifest/uses-feature-element#hw-features
